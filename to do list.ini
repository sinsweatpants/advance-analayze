حاضر. أدناه «التفصيل الإجرائي خطوة-بخطوة» لتنفيذ **الخطة الموحّدة بعد دمج كل المراحل** كما في ملفك «السياق الهندسي.md». يشمل الأوامر، البارامترات الافتراضية، ومتطلّبات الحوسبة، ويعمل بمنظومة TypeScript/Node.js من الصفر حتى التقارير النهائية (PDF/CSV). 

---

# 0) المتطلبات المسبقة (مرة واحدة)

* نظام تشغيل: Linux/Windows/macOS.
* Node.js ≥ 20، pnpm ≥ 9، TypeScript ≥ 5.4.
* Docker (مستحسن لتشغيل Postgres/Redis بسرعة).
* موارد موصى بها للآلة: 8 أنوية CPU، 16–32GB RAM. (انظر الجدول في §8).

**تشغيل قواعد البيانات (Docker)**

```bash
docker run -d --name preprod-pg -e POSTGRES_PASSWORD=dev -e POSTGRES_DB=preprod \
  -p 5432:5432 postgres:16

docker run -d --name preprod-redis -p 6379:6379 redis:7
```

---

# 1) تهيئة المشروع والمونو-ريبو

```bash
mkdir preprod-analyzer && cd preprod-analyzer
pnpm init -y
```

**pnpm workspaces**

```bash
cat > pnpm-workspace.yaml <<'YAML'
packages:
  - "apps/*"
  - "packages/*"
YAML
```

**tsconfig الأساس**

```bash
cat > tsconfig.base.json <<'JSON'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "strict": true,
    "noUncheckedIndexedAccess": true,
    "resolveJsonModule": true,
    "outDir": "dist",
    "types": ["node"],
    "skipLibCheck": true
  }
}
JSON
```

**هيكل المجلدات**

```bash
mkdir -p apps/api apps/worker \
  packages/{core,ingest-normalize,segment-beats,features-stylometry,topics-modeling,sentiment-hybrid,transformers-tasks,fusion-risk,explainability,reporting} \
  configs scripts prisma data/{input,interim,artifacts}
```

---

# 2) تثبيت التبعيات (جذر المونو-ريبو)

```bash
pnpm add -w fastify zod pino pino-pretty dotenv
pnpm add -w @prisma/client prisma
pnpm add -w bullmq ioredis
pnpm add -w @xenova/transformers onnxruntime-node  # استدلال ONNX على CPU
pnpm add -w vega vega-lite vega-lite-api puppeteer
pnpm add -w commander yaml globby dayjs lodash nanoid
pnpm add -w @types/node typescript tsx
# مُعالجات عربية أساسية للتطبيع والتجزئة
pnpm add -w arabic-persian-normalizer he
```

**البيئة**

```bash
cat > .env.example <<'ENV'
DATABASE_URL="postgresql://postgres:dev@localhost:5432/preprod"
REDIS_URL="redis://localhost:6379"
PORT=8080
ENV
cp .env.example .env
```

---

# 3) Prisma (المخطط الأدنى المتوافق)

```bash
cat > prisma/schema.prisma <<'PRISMA'
datasource db { provider = "postgresql"; url = env("DATABASE_URL") }
generator client { provider = "prisma-client-js" }

model Script {
  id        String   @id @default(cuid())
  title     String?
  language  String   @default("ar")
  createdAt DateTime @default(now())
  scenes    Scene[]
}

model Scene {
  id         String   @id @default(cuid())
  number     Int
  heading    String
  location   String?
  timeOfDay  String?
  characters String[]
  text       String
  beats      Beat[]
  scriptId   String
  script     Script   @relation(fields: [scriptId], references: [id])
}

model Beat {
  id       String   @id @default(cuid())
  index    Int
  text     String
  sceneId  String
  scene    Scene     @relation(fields: [sceneId], references: [id])
}
PRISMA

pnpm prisma generate
```

---

# 4) القيم الافتراضية المركزية (configs/defaults.ts)

> تُستخدم كقِيَم افتراضية لجميع وحدات 5.x و6.x

```ts
export const defaults = {
  ingest: { useOCR: false, normalizeRTL: true, digits: "auto", stripTatweel: true, unifyPunct: true },
  segment: {
    sceneHeaderRegex: "^(INT\\.|EXT\\.|INT\\/EXT\\.|داخلي|خارجي)",
    crfEnable: true, crfCtx: 2, beating: "texttiling", ttBlock: 14, ttSmoothing: 2,
    aliasResolution: true, speakerLinking: "hybrid"
  },
  features: { mtld: true, hdd: true, yulesK: true, posTagger: "custom-ar", syntaxDepth: true, keyphrases: "keybert", kpTopk: 8, prodLoad: true },
  topics: { bowMinDf: 2, bowMaxDf: 0.9, ldaEnable: true, ldaK: 20, ldaPasses: 10,
            embedModel: "Xenova/paraphrase-multilingual-MiniLM-L12-v2",
            minClusterSize: 8, eps: 0.7, umapNeighbors: 15, umapDim: 5 },
  sentiment: { lexicon: "ar-drama", negationScope: 4,
               transformer: "Xenova/bert-base-multilingual-uncased-sentiment",
               maxLen: 256, sarcasmClf: true, sarcasmThresh: 0.65,
               smoothing: "loess", loessSpan: 0.2 },
  xformer: { encoder: "Xenova/bert-base-multilingual-cased", maxLen: 512,
             chunkStride: 64, longSeq: "auto", longModel: "Xenova/longformer-base-4096",
             attentionWindow: 512, quantization: "int8", lora: false, calibration: "isotonic" },
  fusion: { strategy: "stacked", metaModel: "logreg", classWeight: "balanced",
            uncertainty: "conformal", alpha: 0.1,
            shapeWeights: { dSent: 0.35, topicShift: 0.25, styleShift: 0.20, conflict: 0.20 } }
} as const;
```

---

# 5) تنفيذ المراحل (5.x) كوحدات قابلة للتشغيل

> كل حزمة سيكون لها `src/index.ts` (API)، و`src/cli.ts` (أوامر)، ويمكن لاحقاً إضافة `src/server.ts` لواجهة HTTP.

## 5.0 الاستيعاب والتطبيع — packages/ingest-normalize

**أمر التشغيل (CLI)**

```bash
pnpm --filter ingest-normalize exec tsx src/cli.ts \
  --input data/input/sample.fdx \
  --use-ocr false --normalize-rtl true --digits auto --strip-tatweel true --unify-punct true \
  --output data/interim/00_ingested.json
```

**افتراضيات مهمة**

* `use-ocr=false` (يتحوّل تلقائياً لـ true عند PDF مصوّر).
* `digits=auto` (تحويل هندي↔عربي حسب الغلبة).
  **حوسبة**: CPU فقط؛ 2–4 أنوية، RAM 2–4GB.

---

## 5.1 التقسيم والتهيئة — packages/segment-beats

**أمر التشغيل**

```bash
pnpm --filter segment-beats exec tsx src/cli.ts \
  --input data/interim/00_ingested.json \
  --scene-header "^(INT\\.|EXT\\.|INT\\/EXT\\.|داخلي|خارجي)" \
  --crf-enable true --crf-ctx 2 \
  --beating texttiling --tt-block 14 --tt-smoothing 2 \
  --speaker-linking hybrid --alias-resolution true \
  --output data/interim/01_scenes_beats.json
```

**حوسبة**: CPU 4–8 أنوية؛ زمن خطي بطول النص.

---

## 5.2 الخصائص التقليدية — packages/features-stylometry

**أمر التشغيل**

```bash
pnpm --filter features-stylometry exec tsx src/cli.ts \
  --input data/interim/01_scenes_beats.json \
  --mtld --hdd --yules-k --pos custom-ar --syntax-depth \
  --keyphrases keybert --kp-topk 8 \
  --prod-load \
  --output data/interim/02_features.json
```

**حوسبة**: CPU 8 أنوية مُستحسن؛ RAM ~4–8GB.

---

## 5.3 نمذجة الموضوعات — packages/topics-modeling

**أمر التشغيل**

```bash
pnpm --filter topics-modeling exec tsx src/cli.ts \
  --input data/interim/01_scenes_beats.json \
  --bow-min-df 2 --bow-max-df 0.9 \
  --lda-enable true --lda-k 20 --lda-passes 10 \
  --bertopic true --min-cluster-size 8 --eps 0.7 \
  --umap-neighbors 15 --umap-dim 5 \
  --output data/interim/03_topics.json
```

**حوسبة**: CPU كافٍ؛ GPU اختياري لتسريع التضمينات.

---

## 5.4 تحليل المشاعر الهجين — packages/sentiment-hybrid

**أمر التشغيل**

```bash
pnpm --filter sentiment-hybrid exec tsx src/cli.ts \
  --input data/interim/01_scenes_beats.json \
  --lexicon ar-drama --negation-scope 4 \
  --transformer "Xenova/bert-base-multilingual-uncased-sentiment" --max-len 256 \
  --sarcasm-clf --sarcasm-thresh 0.65 \
  --smoothing loess --loess-span 0.2 \
  --output data/interim/04_sentiment.json
```

**حوسبة**: يُفضَّل CPU قوي أو GPU؛ RAM 8–12GB.

---

## 5.5 مهام المحوّلات — packages/transformers-tasks

**أمر التشغيل**

```bash
pnpm --filter transformers-tasks exec tsx src/cli.ts \
  --input data/interim/01_scenes_beats.json \
  --tasks "scene_intent,style_markers,conflict_signals" \
  --encoder "Xenova/bert-base-multilingual-cased" --max-len 512 \
  --chunk-stride 64 \
  --long-seq auto --long-model "Xenova/longformer-base-4096" --attention-window 512 \
  --quantization int8 --lora false \
  --calibration isotonic \
  --output data/interim/05_transformers.json
```

**حوسبة**: مستحسن GPU 16–24GB لسياقات طويلة؛ CPU ممكن بوقت أطول.

---

## 5.6 الدمج + 5.7 مؤشرات الخطر — packages/fusion-risk

**أمر التشغيل**

```bash
pnpm --filter fusion-risk exec tsx src/cli.ts \
  --features data/interim/02_features.json \
  --topics   data/interim/03_topics.json \
  --sent     data/interim/04_sentiment.json \
  --xformer  data/interim/05_transformers.json \
  --strategy stacked --meta-model logreg --class-weight balanced \
  --uncertainty conformal --alpha 0.1 \
  --risk-formula default_v1 \
  --output data/interim/06_fusion_risk.json
```

**المعادلات الافتراضية**

* **ExecComplexity**:

  ```
  1.2*LocationSwitch + 0.9*CrowdIntensity + 1.1*NightExt + 1.3*StuntsVFX + 0.6*DialogueDensity
  ```
* **shape_value (0–100)**:

  ```
  0.35*Δsentiment + 0.25*topic_shift + 0.20*style_shift + 0.20*conflict_signals
  ```

**حوسبة**: CPU 4–8 أنوية؛ RAM 4–8GB.

---

# 6) قابلية التفسير (6.x) — packages/explainability

**أمر التشغيل**

```bash
pnpm --filter explainability exec tsx src/cli.ts \
  --fusion data/interim/06_fusion_risk.json \
  --text   data/interim/01_scenes_beats.json \
  --methods "lime,perm_importance,attention_rollout" \
  --topk-evidence 10 \
  --output data/interim/07_explanations.json
```

**حوسبة**: SHAP/LIME على عينات؛ RAM 8–16GB؛ GPU يفيد في تسريع العينات الكبيرة.

---

# 7) التقارير والتصدير — packages/reporting

**أمر التشغيل**

```bash
pnpm --filter reporting exec tsx src/cli.ts \
  --fusion  data/interim/06_fusion_risk.json \
  --sent    data/interim/04_sentiment.json \
  --topics  data/interim/03_topics.json \
  --scenes  data/interim/01_scenes_beats.json \
  --explain data/interim/07_explanations.json \
  --export-pdf "data/artifacts/report_preprod_dossier.pdf" \
  --export-csv "data/artifacts/report_metrics.csv"
```

**حوسبة**: CPU؛ Puppeteer يحتاج ~1–2GB RAM أثناء التوليد.

---

# 8) التشغيل الشامل (Orchestration) — scripts/run-pipeline.ts

**أمر واحد للسلسلة كاملة**

```bash
pnpm tsx scripts/run-pipeline.ts \
  --config configs/defaults.ts \
  --input data/input/sample.fdx \
  --export-pdf true --export-csv true
```

**ترتيب التنفيذ داخل السكربت**

```
ingest → segment → features → topics → sentiment → transformers → fusion → explain → report
```

---

# 9) واجهة API (اختياري للتكامل السريع)

**تشغيل خادم Fastify**

```bash
pnpm --filter api exec tsx src/server.ts
```

**النقاط الأساسية**

* `POST /ingest`
* `POST /analyze` (tasks[])
* `POST /explain`
* `GET /reports/:scriptId`

---

# 10) متطلّبات الحوسبة (ملخّص)

| المرحلة | CPU (أنوية) |     RAM | GPU (VRAM) | ملاحظات                   |
| ------- | ----------: | ------: | ---------: | ------------------------- |
| 5.0–5.2 |         4–8 |   4–8GB |          — | OCR عند الحاجة فقط        |
| 5.3     |         4–8 |  8–12GB |    اختياري | التضمينات أسرع مع GPU     |
| 5.4     |         4–8 |  8–12GB |     8–12GB | سخرية + تعدد أبعاد        |
| 5.5     |           8 | 12–24GB |    16–24GB | Longformer للنصوص الطويلة |
| 5.6–5.7 |         4–8 |   4–8GB |          — | خفيف نسبيًا               |
| 6.x     |         4–8 |  8–16GB |    12–16GB | عينات تفسير كبيرة         |

---

# 11) سياسات الفشل الرحيمة (Fail-soft)

* تعذّر BERTopic ⇒ الرجوع إلى LDA+Keyphrases مع `degraded:true`.
* عجز Longformer ⇒ تفعيل chunking + تجميع logits.
* فشل وحدة واحدة لا يوقف السلسلة؛ تُسجَّل الأسباب في `artifacts/logs/*.jsonl`.

---

# 12) نقاط ضبط سريعة

* نصوص قصيرة: خفّض `ldaK` إلى 12–15.
* موضوعات هشّة: ارفع `minClusterSize` إلى 12.
* اهتزاز المشاعر: غيّر `loessSpan` بين 0.15–0.30.
* بطء الاستدلال: خفّض `maxLen` إلى 384، أو عطّل `longSeq`.

---

**المخرجات المتوقّعة بعد التشغيل الشامل**

* `data/artifacts/report_preprod_dossier.pdf`
* `data/artifacts/report_metrics.csv`
* JSONات المراحل: `00_ingested.json` → `07_explanations.json`

هذه الخطة «تنفيذية خالصة» ومطابقة لملفك الموحّد، وتكفي لبدء العمل فورًا وتشغيل المشروع End-to-End دون الرجوع لأي مصادر خارجية. 
